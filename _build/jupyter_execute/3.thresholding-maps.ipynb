{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63f72679-d1d8-4dbe-90e6-df28aa84fd99",
   "metadata": {},
   "source": [
    "# Thresholding Statistical Maps\n",
    "As we have seen previously, once we have our image of test statistics, the classical approach would be to refer to the null distribution of the $t$-statistic and then calculate $p$-values. At the beginning of the last section, we saw how we could also do this with our images of $t$-statistics, identifying which voxels were significant using the tradition $p < 0.05$ criterion. We can then use this information to *threshold* our statistical map, which will be the focus of this section.\n",
    "\n",
    "When we talk about *thresholding* an image, we essentially mean making some voxels invisible using a cut-off value. This serves the purpose of only letting us only see the values that we care about in an image. Because this turns the image into a set of regional results, it can be difficult to make sense of a purely thresholded image. As such, we normally display the thresholded image on top of another image that we can use for localisation purposes. If the data is normalised, we can use an MNI template for this, as illustrated in {numref}`threshold-t-fig`.\n",
    "\n",
    "```{figure} images/threshold-t.png\n",
    "---\n",
    "width: 800px\n",
    "name: threshold-t-fig\n",
    "---\n",
    "Illustration of how an image of $t$-statistics can be thresholded by making certain voxels invisible. For interpretation, the thresholded image can be overlaid on another image, typically a template in standard space.\n",
    "```\n",
    "\n",
    "In terms of the cut-off value we choose, this can either be a value within the image itself (e.g. a value of $t$), a value from another image that is aligned, or a value that can be calculated using the voxel values in the image. For our image of $t$-statistics, it makes most sense to threshold based on the associated $p$-value at each voxel. For example, the image overlaid below is the result of thresholding an image of $t$-statistics based on setting any voxel where $p > 0.05$ equal to 0. Voxels with a value of 0 are then displayed as transparent by the image viewing software. Notice that there are *a lot* of results here. The reasons for this will be discussed later in the lesson.\n",
    "\n",
    "<iframe src=\"spm152.html\" width=\"800\" height=\"600\" frameborder=\"0\" scrolling=\"no\" title=\"\"></iframe>\n",
    "\n",
    "It is important that you understand what this is showing you, because this is how your final results will be displayed in `SPM`. Remember, the voxels in hot colours represent $t$-statistic values that have an associated $p$-value *below* our chosen threshold. In this example we have used $p < 0.05$, but a different threshold will cause a different set of voxels to be visible. This is important because any time you see imaging results like this you need to immediately think about what threshold was used. Given how important this choice is, the remainder of this lesson will be about developing different approaches to thresholding a statistical map.\n",
    "\n",
    "````{important}\n",
    "Before moving on, there is one important detail about how $p$-values are calculated for $t$-statistics in `SPM`. When `SPM` calculates a $p$-value for an associated $t$-value, it only uses the *upper-tail* of the null distribution. Practically, this means that the $t$-values need to be *positive* in order for the $p$-value to be significant. As shown in {numref}`upper-tail-p-fig`, a negative $t$-statistic will always result in a large $p$-value, even though this represent the *same magnitude* of effect in the opposite direction. Technically, this makes any hypothesis test in `SPM` that uses $t$-statistics a *one-tailed* hypotheses.\n",
    "\n",
    "```{figure} images/upper-tail-p.png\n",
    "---\n",
    "width: 800px\n",
    "name: upper-tail-p-fig\n",
    "---\n",
    "Illustration of how the $p$-values for $t$-statistics calculated in SPM are *upper-tail*, meaning we only see significant effects for $t$-values that are both *large* and *positive*.\n",
    "```\n",
    "\n",
    "In terms of interpretation, using only upper-tail $p$-values means that we will only see significant results when the direction of the contrast matches the direction of the effect. To understand what this means, consider a simple example where we have condition `A` and condition `B`. If we use the contrast weights $[1, -1]$ we will only see significant effects in places where the signal for `A` is larger than `B`. Conversely, if we used the contrast weights $[-1, 1]$ we would only see significant effects in places where the signal for `B` is larger than `A`.\n",
    "\n",
    "From this, we can test different directional hypotheses using different signs for the weights. Because of this, it is usual to describe these contrasts in terms of the direction they are testing. So, $[1, -1]$ would be described as \"Condition A > Condition B\" and $[-1, 1]$ would be described as \"Condition B > Condition A\". This will be clearer once you have a go at specifying contrasts in `SPM`. Just try and remember that $t$-contrasts in SPM are *directional one-tailed* tests, and that the sign of the weights determines the direction of effect that you are testing.\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b842cf-11f7-4b13-b942-2f92e0751111",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MATLAB Kernel",
   "language": "matlab",
   "name": "jupyter_matlab_kernel"
  },
  "language_info": {
   "file_extension": ".m",
   "mimetype": "text/x-matlab",
   "name": "matlab"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}