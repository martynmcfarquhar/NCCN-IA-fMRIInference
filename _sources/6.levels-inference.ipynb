{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63f72679-d1d8-4dbe-90e6-df28aa84fd99",
   "metadata": {},
   "source": [
    "# Levels of Inference\n",
    "At this point, we are nearly at the end of our journey towards having some actual results. We have seen how to ask questions of our data using contrasts, create statistical maps from those contrasts and then finally threshold those maps using $p$-values corrected for multiple comparisons. At this stage, we could just stop and declare our findings based on where in the brain we see results after thresholding. However, there is one final choice we have to make in terms of our *level of inference*. This choice is based on the fact that the results at individual voxels are not necessarily the most interesting feature of an image. As such, we may want to evaluate our results using some other criteria that takes into account the *topology* of our statistical map.\n",
    "\n",
    "## Features of an Image\n",
    "Although our analysis has so far treated our image as a collection of individual datasets at each voxel, we know that in reality there are spatial connections between those voxels. So far, we have basically ignored this. However, we should really think of our images as a set of *topological features*. To see this, consider the slice through a statistical map shown in {numref}`func-flat-intensity-fig`. Looking at the image this way shows how we have a *landscape* of features, consisting of mountains and valleys of test statistics across the image.\n",
    "\n",
    "```{figure} images/func-flat-intensity.png\n",
    "---\n",
    "width: 800px\n",
    "name: func-flat-intensity-fig\n",
    "---\n",
    "Illustration of how a statistical map can be considered a landscape of topological features, rather than just individual tests at each voxel.\n",
    "```\n",
    "\n",
    "To make this a little simpler, consider the 1D slice through an image shown in {numref}`image-landscape-1d-fig`.\n",
    "\n",
    "```{figure} images/image-landscape-1d.png\n",
    "---\n",
    "width: 800px\n",
    "name: image-landscape-1d-fig\n",
    "---\n",
    "Illustration of a 1D slice through a test statistic image, highlighting how both the *peaks* and *spatial extent* of the test statistics may be of interest.\n",
    "```\n",
    "\n",
    "Taking this plot into account, we can identify two types of topological feature that may be of interest. One feature is the *peaks* of the signal, corresponding to the *largest* test statistics within the image. On the left we can see a very obvious spike corresponding to a single large test statistic value. The second feature is the *spatial extent* of the signal. For instance, on the right we can see a hill of points which seems to indicate some connection between the neighbouring voxels, even if no single voxel has a particularly large test statistic value. So far in this lesson we have focused on individual voxels, which is to say we have only been looking at the *peaks* in the image. However, there is an argument to say that looking for the *spatial extent* of the signal is more meaningful. After all, how much do we trust a single voxel versus multiple voxels that appear to show a consistent effect? This distinction is an example of the final choice we have to make, namely do we focus on the largest statistics or do we focus on the spatial extent of the signal? This distinction is referred to as performing either *voxel-level* inference or *cluster-level* inference.\n",
    "\n",
    "## Voxel-level Inference\n",
    "The approach we have taken so far, in terms of calculating a test statistic and $p$-value at each voxel, is known as *voxel-level* inference. As illustrated in {numref}``, this involves specifying a threshold $u$ and then declaring any voxel above that threshold as significant. As discussed in the last section, this threshold can be derived from uncorrected $p$-values, FWE-corrected $p$-values or FDR-corrected $p$-values.\n",
    "\n",
    "```{admonition} Why Choose Voxel-level Inference?\n",
    "The advantage of voxel-level inference is that it is the most spatially-specific approach. This is because we can point to any voxel with a significant $p$-value and say \"there was a significant effect here\". This means we can *localise* effects with great accuracy. However, the disadvantage is that voxel-level inference is the more *conservative* approach. In addition, we have to think about how useful or realistic it is to find a single result at a single voxel? Surely we expect some degree of spatial extent to the signal, given that a real brain is not neatly compartmentalised into discrete voxel units. Voxel-level inference does not take this into account. As such, it is not uncommon for only a single voxel to survive correction. When this happens, we have to consider the biological plausibility of a significant change in signal only occurring within a very specific $3mm^{3}$ region of the brain.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d08257-9044-495b-9385-be9457ce33e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MATLAB Kernel",
   "language": "matlab",
   "name": "jupyter_matlab_kernel"
  },
  "language_info": {
   "file_extension": ".m",
   "mimetype": "text/x-matlab",
   "name": "matlab"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
